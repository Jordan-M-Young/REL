{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385de3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd722fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"./data\"\n",
    "wiki_version = \"wiki_2019\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ad609",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pympler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d62eeea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588c8fd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8e8f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-19 21:05:20,077 --------------------------------------------------------------------------------\n",
      "2021-12-19 21:05:20,079 The model key 'ner-fast' now maps to 'https://huggingface.co/flair/ner-english-fast' on the HuggingFace ModelHub\n",
      "2021-12-19 21:05:20,081  - The most current version of the model is automatically downloaded from there.\n",
      "2021-12-19 21:05:20,082  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner-fast/en-ner-fast-conll03-v0.4.pt)\n",
      "2021-12-19 21:05:20,084 --------------------------------------------------------------------------------\n",
      "2021-12-19 21:05:20,790 loading file /Users/vanhulsm/.flair/models/ner-english-fast/4c58e7191ff952c030b82db25b3694b58800b0e722ff15427f527e1631ed6142.e13c7c4664ffe2bbfa8f1f5375bd0dced866b8c1dd7ff89a6d705518abf0a611\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4adb9bb12f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msyntok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmenter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ner-fast\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0min_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'msmarco_doc_00.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/Users/vanhulsm/Desktop/msmarco_v2_doc_sample/msmarcov2/{in_file}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3/lib/python3.9/site-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# see https://github.com/zalandoresearch/flair/issues/351\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_big_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_model_with_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;31m# Lets us override the imports that pickle uses when unpickling an object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;31m# This is useful for maintaining BC if we change a module path that tensor instantiation relies on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import time, json, gzip\n",
    "import syntok.segmenter as segmenter\n",
    "\n",
    "tagger = SequenceTagger.load(\"ner-fast\")\n",
    "in_file = 'msmarco_doc_00.gz'\n",
    "data_path = f'/Users/vanhulsm/Desktop/msmarco_v2_doc_sample/msmarcov2/{in_file}'\n",
    "\n",
    "sample_size = 50 # Change to bigger number for better estimate\n",
    "batch_size = 10 # Change to value that batch fits ~60% avg? GPU mem\n",
    "\n",
    "batch = []\n",
    "lines = []\n",
    "with gzip.open(data_path, 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if (i+2) % sample_size == 0:\n",
    "            break\n",
    "        document = json.loads(line)\n",
    "        url, title, headings, body, docid = (document['url'], document['title'],\n",
    "            document['headings'], document['body'], document['docid'])\n",
    "        for paragraph in segmenter.process(body):\n",
    "            for sentence in paragraph:\n",
    "                s = ' '.join([sen.value for sen in sentence])\n",
    "                lines.append(s)\n",
    "\n",
    "docs = {f'doc_{i}': [' '.join(lines[i*5:((i+1)*5)]), []] for i in range(100, 250)}# = \" \".join(lines[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7a48cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading aida_train\n",
      "Loading aida_testA\n",
      "Loading aida_testB\n",
      "Loading wned-ace2004\n",
      "Loading wned-aquaint\n",
      "Loading wned-clueweb\n",
      "Loading wned-msnbc\n",
      "Loading wned-wikipedia\n",
      "length docs is 50.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from REL.training_datasets import TrainingEvaluationDatasets\n",
    "\n",
    "datasets = TrainingEvaluationDatasets(base_url, wiki_version).load()[\"aida_testB\"]\n",
    "\n",
    "server = True\n",
    "docs = {}\n",
    "for i, doc in enumerate(datasets):\n",
    "    sentences = []\n",
    "    for x in datasets[doc]:\n",
    "        if x[\"sentence\"] not in sentences:\n",
    "            sentences.append(x[\"sentence\"])\n",
    "    text = \". \".join([x for x in sentences])\n",
    "    docs[i] = [text, []]\n",
    "    if len(docs) == 150:\n",
    "        print(\"length docs is 50.\")\n",
    "        print(\"====================\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71014f4f",
   "metadata": {},
   "source": [
    "# Mention detection\n",
    "Bottlenecks:\n",
    "1. SQLite3 is too slow, try array-based approach.\n",
    "2. Flair is too slow:\n",
    "    - Try different model (e.g. replace LSTM with CNN+LSTM), can also stop using Flair.\n",
    "    - Convert to ONNX\n",
    "    - ... \n",
    "3. Wikipedia2Vec is too time-consuming to train, should be quite easy to replace with PyTorch and sparse embs.\n",
    "    - Data format is quite tedious to use though.\n",
    "    - HashEmbeddings? Result in ~110.000.900 parameters, which in turn would result in ~419MB memory usage when using float32.\n",
    "    - Alternatively, we can tokenize entities and share parameters across different entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4267200",
   "metadata": {},
   "source": [
    "## Process intermediate results Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "883ee0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-19 21:06:21,414 --------------------------------------------------------------------------------\n",
      "2021-12-19 21:06:21,417 The model key 'ner-fast' now maps to 'https://huggingface.co/flair/ner-english-fast' on the HuggingFace ModelHub\n",
      "2021-12-19 21:06:21,417  - The most current version of the model is automatically downloaded from there.\n",
      "2021-12-19 21:06:21,418  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner-fast/en-ner-fast-conll03-v0.4.pt)\n",
      "2021-12-19 21:06:21,419 --------------------------------------------------------------------------------\n",
      "2021-12-19 21:06:21,956 loading file /Users/vanhulsm/.flair/models/ner-english-fast/4c58e7191ff952c030b82db25b3694b58800b0e722ff15427f527e1631ed6142.e13c7c4664ffe2bbfa8f1f5375bd0dced866b8c1dd7ff89a6d705518abf0a611\n"
     ]
    }
   ],
   "source": [
    "from REL.ner import load_flair_ner\n",
    "\n",
    "tagger_ner = load_flair_ner(\"ner-fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "358fe7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import REL\n",
    "from REL.entity_disambiguation import EntityDisambiguation\n",
    "from REL.mention_detection import MentionDetection\n",
    "from REL.utils import process_results\n",
    "\n",
    "mention_detection = MentionDetection(base_url, wiki_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bc151e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset, \n",
    " dataset_sentences_raw, \n",
    " processed_sentences, \n",
    " splits) = mention_detection.process_and_predict_flair(docs, tagger_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96eaad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Store intermediate results\n",
    "with open('./data/intermediate_flair_res.pkl', 'wb') as f:\n",
    "    pickle.dump([dataset, dataset_sentences_raw, processed_sentences, splits], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5be763",
   "metadata": {},
   "source": [
    "## Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05d3e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f02d8ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Store intermediate results\n",
    "with open('./data/intermediate_flair_res.pkl', 'rb') as f:\n",
    "    dataset, dataset_sentences_raw, processed_sentences, splits = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a01f3e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:12<00:00, 12.46it/s]\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import REL\n",
    "from REL.entity_disambiguation import EntityDisambiguation\n",
    "from REL.mention_detection import MentionDetection\n",
    "from REL.utils import process_results\n",
    "\n",
    "mention_detection = MentionDetection(base_url, wiki_version)\n",
    "results, total_ment = mention_detection.process_predictions_flair(dataset, dataset_sentences_raw, processed_sentences, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e98db451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiler Report\n",
      "\n",
      "Action            \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Total             \t|  -              \t|_              \t|  12.117         \t|  100 %          \t|\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "get_candidates    \t|  0.0022919      \t|3198           \t|  7.3296         \t|  60.5 %         \t|\n",
      "preprocess_mention\t|  0.00081884     \t|3198           \t|  2.6187         \t|  21.6 %         \t|\n",
      "get_ctxt          \t|  0.00059791     \t|2861           \t|  1.7106         \t|  14.1 %         \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "print(mention_detection.profiler.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "067662f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all mentions\n",
    "mentions = []\n",
    "for k, v in results.items():\n",
    "    for ment in v:\n",
    "        mentions.append(ment['mention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea1ace8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2861/2861 [00:06<00:00, 418.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 6.840s, average time taken 0.0023907366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Benchmark preprocess_mention (note that these mentions are already processed)\n",
    "mention_candidates = {}\n",
    "\n",
    "import time\n",
    "start = time.monotonic()\n",
    "for m in tqdm(mentions):\n",
    "    cands = mention_detection.get_candidates(m)\n",
    "    mention_candidates[m] = cands\n",
    "time_taken = time.monotonic()-start\n",
    "\n",
    "print(f'Total time taken {time_taken:.3f}s, average time taken {time_taken/len(mentions):.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581cf9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asizeof.asizeof(np.array(['aa', 'aa', 'aa', 'aa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b79f4b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2861/2861 [00:00<00:00, 953963.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0.005s, average time taken 0.0000018032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get potential increase when using dict\n",
    "start = time.monotonic()\n",
    "\n",
    "for m in tqdm(mentions):\n",
    "    cands = mention_candidates[m]\n",
    "time_taken = time.monotonic()-start\n",
    "\n",
    "print(f'Total time taken {time_taken:.3f}s, average time taken {time_taken/len(mentions):.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d06f98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx 8151KBs memory usage for 1309 mentions and their candidates\n"
     ]
    }
   ],
   "source": [
    "print(f'Approx {asizeof.asizeof(mention_candidates) // 1024 }KBs memory usage for {len(mention_candidates)} mentions and their candidates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c30781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx 169KBs memory usage for 1309 mentions and their candidates\n"
     ]
    }
   ],
   "source": [
    "print(f'Approx {asizeof.asizeof({np.int16(i) for i, (k, v) in enumerate(mention_candidates.items())}) // 1024 }KBs memory usage for {len(mention_candidates)} mentions and their candidates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf271b0e",
   "metadata": {},
   "source": [
    "# Efficiently represent mentions and their entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d93b0c",
   "metadata": {},
   "source": [
    "## Preliminary index building using Python native data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f4c9afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1309/1309 [00:00<00:00, 22223.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "330264"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "mention_entity_references = {}\n",
    "all_entities = {}\n",
    "ent_probability = {}\n",
    "\n",
    "max_length_ment = -1\n",
    "\n",
    "idx_ment = 0\n",
    "idx_ent = 0\n",
    "\n",
    "def process_entities(entities,\n",
    "                     all_entities, \n",
    "                     ent_probability):\n",
    "    processed_entities = []\n",
    "    for entity, prob in entities:\n",
    "        # If value not exists, replace with index\n",
    "        ent_index = all_entities.get(entity, -1)\n",
    "        prob_index = ent_probability.get(prob, -1)\n",
    "        \n",
    "        if prob_index == -1:\n",
    "            prob_index = len(ent_probability)\n",
    "            ent_probability[prob] = prob_index\n",
    "        \n",
    "        if ent_index == -1:\n",
    "            ent_index = len(all_entities)\n",
    "            all_entities[entity] = ent_index\n",
    "\n",
    "        processed_entities.append([ent_index, \n",
    "                                   prob_index])\n",
    "    return (processed_entities, \n",
    "            all_entities, \n",
    "            ent_probability)\n",
    "\n",
    "for ment, entities in tqdm(mention_candidates.items()):\n",
    "    \n",
    "    # Mentions of length refers to specific mention that will be ordered    \n",
    "    processed_entities, all_entities, ent_probability = process_entities(entities, \n",
    "                                                                        all_entities,\n",
    "                                                                        ent_probability \n",
    "                                                                        )\n",
    "    \n",
    "    n_entities = len(processed_entities)\n",
    "    mention_entity_references[ment] = np.array(processed_entities, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adb195",
   "metadata": {},
   "source": [
    "## Convert to Numpy array objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86238c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3841"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_size = 0\n",
    "\n",
    "# Convert mentions and ment/entity references.\n",
    "tot_size += asizeof.asizeof(mention_entity_references)\n",
    "\n",
    "# Convert entity for index lookup.\n",
    "arr_all_entities = np.array(list(all_entities.keys()), dtype=object)\n",
    "\n",
    "tot_size += asizeof.asizeof(list(all_entities.keys()))\n",
    "\n",
    "# Convert array probabilities\n",
    "arr_probs = np.array(list(ent_probability.keys()), dtype=np.float16)\n",
    "\n",
    "tot_size += asizeof.asizeof(arr_probs)\n",
    "\n",
    "# Number of KBs\n",
    "tot_size // 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded5361",
   "metadata": {},
   "source": [
    "## Look-up speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e40f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite: mean = 0.0016143512, total time = 4.598s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73df1b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2848/2848 [00:00<00:00, 16921.74it/s]\n",
      "100%|██████████| 1309/1309 [00:00<00:00, 14195.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 0.0560099000s, \n",
      "    mean per ment 0.0000196664, \n",
      "    std per ment 0.0000256856, \n",
      "    max per ment 0.0009202860, \n",
      "    min per ment 0.0000104540\n",
      "All tests passed, array is equal to dictionary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get potential increase when using dict\n",
    "'''\n",
    "TODO:\n",
    "1. Create .py file and class, convert to pickled files.\n",
    "2. Measure RAM usage as .py file when loading all into memory.\n",
    "3. Report to RU with next steps <-- probably makes sense to keep mention_candidates_lookup in memory and the remainder with their indexes\n",
    "in a Redis table or something.\n",
    "\n",
    "The indexes refer to both entity_embeddings, entity_names and their probabilities, so can be done in one bulk lookup.\n",
    "\n",
    "But as `mention_candidates_lookup` remains in-memory, preprocess_mention remains untouched.\n",
    "\n",
    "'''\n",
    "\n",
    "mention_candidates_lookup = collections.defaultdict(dict)\n",
    "times = []\n",
    "\n",
    "for m in tqdm(mentions):\n",
    "    start = time.monotonic()\n",
    "    \n",
    "    # Lookup entities\n",
    "    entity_identifiers = mention_entity_references[m]\n",
    "    \n",
    "    entity_strings = arr_all_entities[entity_identifiers[:,0]]\n",
    "    entity_probs = arr_probs[entity_identifiers[:,1]]\n",
    "    \n",
    "    result = np.stack((entity_strings, entity_probs)).T\n",
    "    \n",
    "    times.append(time.monotonic()-start)\n",
    "        \n",
    "    # This is solely done for validity checks, so excluded from time test\n",
    "    for ent_str, ent_prob in result:\n",
    "        mention_candidates_lookup[m][ent_str] = ent_prob\n",
    "\n",
    "print(\n",
    "    f\"\"\"Time taken {sum(times):.10f}s, \n",
    "    mean per ment {np.mean(times):.10f}, \n",
    "    std per ment {np.std(times):.10f}, \n",
    "    max per ment {np.max(times):.10f}, \n",
    "    min per ment {np.min(times):.10f}\"\"\"\n",
    ")\n",
    "\n",
    "# Compare between array-based lookups and original\n",
    "for mention, entities in tqdm(mention_candidates.items()):\n",
    "    lookup = mention_candidates_lookup[mention]\n",
    "    \n",
    "    entities_original = []\n",
    "    assert len(lookup) == len(entities), 'Unequal length of # of entities'\n",
    "    \n",
    "    for e, p in entities:\n",
    "        assert lookup[e] == np.float16(p), 'Probability for entity not equal'\n",
    "        entities_original.append(e)\n",
    "    \n",
    "    lookup_entities = set(list(lookup.keys())).symmetric_difference(entities_original)\n",
    "    assert len(lookup_entities) == 0, 'Entities found that are not present in one anothers sets'\n",
    "print('All tests passed, array is equal to dictionary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2282f",
   "metadata": {},
   "source": [
    "# Clean class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d598697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb01c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entities(entities,\n",
    "                     all_entities, \n",
    "                     ent_probability):\n",
    "    processed_entities = []\n",
    "    for entity, prob in entities:\n",
    "        # If value not exists, replace with index\n",
    "        ent_index = all_entities.get(entity, -1)\n",
    "        prob_index = ent_probability.get(prob, -1)\n",
    "        \n",
    "        if prob_index == -1:\n",
    "            prob_index = len(ent_probability)\n",
    "            ent_probability[prob] = prob_index\n",
    "        \n",
    "        if ent_index == -1:\n",
    "            ent_index = len(all_entities)\n",
    "            all_entities[entity] = ent_index\n",
    "\n",
    "        processed_entities.append([ent_index, \n",
    "                                   prob_index])\n",
    "    return (processed_entities, \n",
    "            all_entities, \n",
    "            ent_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a74244c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23203/23203 [13:47<00:00, 28.04it/s] \n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import REL\n",
    "from REL.entity_disambiguation import EntityDisambiguation\n",
    "from REL.mention_detection import MentionDetection\n",
    "from REL.utils import process_results\n",
    "\n",
    "base_url = \"./data\"\n",
    "wiki_version = \"wiki_2019\"\n",
    "\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "mention_entity_references = {}\n",
    "all_entities = {}\n",
    "ent_probability = {}\n",
    "\n",
    "max_length_ment = -1\n",
    "\n",
    "idx_ment = 0\n",
    "idx_ent = 0\n",
    "\n",
    "mention_detection = MentionDetection(base_url, wiki_version)\n",
    "\n",
    "c = mention_detection.wiki_db.db.cursor()\n",
    "n_rows= c.execute(\"select COUNT(word) from wiki\").fetchone()[0]\n",
    "\n",
    "c = mention_detection.wiki_db.db.cursor()\n",
    "c.execute(\"select word, p_e_m from wiki\")\n",
    "cnt = 0\n",
    "batch_size = 1_000\n",
    "for i in tqdm(range((n_rows//batch_size)+1)):\n",
    "    batch = c.fetchmany(batch_size)\n",
    "    cnt += 1\n",
    "    \n",
    "    for ment, ent_binary in batch:\n",
    "        entities = mention_detection.wiki_db.binary_to_dict(ent_binary)\n",
    "        \n",
    "        # Mentions of length refers to specific mention that will be ordered    \n",
    "        processed_entities, all_entities, ent_probability = process_entities(entities, \n",
    "                                                                            all_entities,\n",
    "                                                                            ent_probability \n",
    "                                                                            )\n",
    "\n",
    "        n_entities = len(processed_entities)\n",
    "        mention_entity_references[ment] = np.array(processed_entities, dtype=np.int32)\n",
    "    \n",
    "    if not batch:\n",
    "        break\n",
    "        \n",
    "    if i % 250 == 0:\n",
    "        # Convert and store intermediately so that we can restart somewhere if needed.\n",
    "        ## Convert entity for index lookup.\n",
    "        arr_all_entities = np.array(list(all_entities.keys()), dtype=object)\n",
    "\n",
    "        ## Convert array probabilities\n",
    "        arr_probs = np.array(list(ent_probability.keys()), dtype=np.float16)\n",
    "\n",
    "        with open(f'./data/ment_cands_lookup_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(mention_entity_references, f)\n",
    "\n",
    "        np.save('./data/arr_entities', arr_all_entities)\n",
    "        np.save('./data/arr_mention_entity_probs', arr_probs)\n",
    "        \n",
    "        mention_entity_references = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87674842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert entity for index lookup.\n",
    "arr_all_entities = np.array(list(all_entities.keys()), dtype=object)\n",
    "\n",
    "# Convert array probabilities\n",
    "arr_probs = np.array(list(ent_probability.keys()), dtype=np.float16)\n",
    "\n",
    "with open(f'./data/ment_cands_lookup_{i}.pkl', 'wb') as f:\n",
    "    pickle.dump(mention_entity_references, f)\n",
    "\n",
    "np.save('./data/arr_entities', arr_all_entities)\n",
    "np.save('./data/arr_mention_entity_probs', arr_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc7284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_size = 0\n",
    "\n",
    "# Convert mentions and ment/entity references.\n",
    "tot_size += asizeof.asizeof(mention_entity_references)\n",
    "tot_size += asizeof.asizeof(arr_probs)\n",
    "tot_size += asizeof.asizeof(list(all_entities.keys()))\n",
    "\n",
    "# Number of KBs\n",
    "tot_size // 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d35295e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "417168 // 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44dd9787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:57<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20e5db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23202365/23202365 [00:13<00:00, 1775728.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "239242"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_bytes = 0\n",
    "for v in tqdm(ment_cands_lookup.values()):\n",
    "    total_bytes += v.nbytes\n",
    "    \n",
    "total_bytes // 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d6add6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045652653959389736"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mention_entity_references) / len(arr_all_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f6f685",
   "metadata": {},
   "source": [
    "# Profile \n",
    "- When loading `arr_all_entities` and `arr_probs`, memory usage is ~464MB. \n",
    "- When also loading `mention_entity_references`, it goes up to ~6800MB, meaning ~6.3GB is used for \n",
    "`mention_entity_references`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Python terminal and test memory usage of:\n",
    "# 1. All three in memory\n",
    "# 2. Only `mention_entity_references` in memory\n",
    "\n",
    "\n",
    "# Test with: \n",
    "# top -pid + ps\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "files = natsorted(os.listdir('./data/'))\n",
    "\n",
    "ment_cands_lookup = {}\n",
    "for dirr in tqdm(files):\n",
    "    if 'ment_cands_lookup' in dirr:\n",
    "        with open(f'./data/{dirr}', 'rb') as f:\n",
    "            tmp = pickle.load(f)\n",
    "        for k, v in tmp.items():\n",
    "            assert k not in ment_cands_lookup, 'Not unique.'\n",
    "            ment_cands_lookup[k] = v\n",
    "\n",
    "arr_all_entities = np.load('./data/arr_entities')\n",
    "arr_probs = np.load('./data/arr_mention_entity_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21cbf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "999da5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0da4e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2861/2861 [00:06<00:00, 431.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 6.5767760050s, \n",
      "    mean per ment 0.0022987683, \n",
      "    std per ment 0.0029809774, \n",
      "    max per ment 0.0401902410, \n",
      "    min per ment 0.0000630020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Benchmark preprocess_mention (note that these mentions are already processed)\n",
    "mention_candidates = {}\n",
    "\n",
    "times = []\n",
    "\n",
    "for m in tqdm(mentions):\n",
    "    start = time.monotonic()\n",
    "    cands = mention_detection.get_candidates(m)\n",
    "    assert len(cands) != 0, 'wut'\n",
    "    times.append(time.monotonic()-start)\n",
    "\n",
    "print(\n",
    "    f\"\"\"Time taken {sum(times):.10f}s, \n",
    "    mean per ment {np.mean(times):.10f}, \n",
    "    std per ment {np.std(times):.10f}, \n",
    "    max per ment {np.max(times):.10f}, \n",
    "    min per ment {np.min(times):.10f}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4e67a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.63930035098763"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0022987683 / 0.0000292318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e495743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2861/2861 [00:00<00:00, 31799.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 0.0836321040s, \n",
      "    mean per ment 0.0000292318, \n",
      "    std per ment 0.0000871654, \n",
      "    max per ment 0.0042386290, \n",
      "    min per ment 0.0000046650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Benchmark preprocess_mention (note that these mentions are already processed)\n",
    "mention_candidates = {}\n",
    "\n",
    "times = []\n",
    "\n",
    "for m in tqdm(mentions):\n",
    "    start = time.monotonic()\n",
    "    \n",
    "    # Lookup entities\n",
    "    entity_identifiers = ment_cands_lookup[m]\n",
    "    entity_strings = arr_all_entities[entity_identifiers[:,0]]\n",
    "    entity_probs = arr_probs[entity_identifiers[:,1]]\n",
    "    \n",
    "    times.append(time.monotonic()-start)\n",
    "    \n",
    "    \n",
    "    #result = np.stack((entity_strings, entity_probs)).T\n",
    "    \n",
    "    \n",
    "print(\n",
    "    f\"\"\"Time taken {sum(times):.10f}s, \n",
    "    mean per ment {np.mean(times):.10f}, \n",
    "    std per ment {np.std(times):.10f}, \n",
    "    max per ment {np.max(times):.10f}, \n",
    "    min per ment {np.min(times):.10f}\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
